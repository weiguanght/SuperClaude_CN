# 反思框架集成 - 项目管理智能体 (PM Agent)

**日期**：2025-10-17
**目的**：将反思 (Reflexion) 自省机制集成到项目管理智能体 (PM Agent) 中。
**来源**：《Reflexion: Language Agents with Verbal Reinforcement Learning》(2023, arXiv)

---

## 概要 (Executive Summary)

Reflexion 是一种让 LLM 智能体能够回顾自己的行为、探测错误并在此后的尝试中进行改进的框架。

### 核心机制

```yaml
传统智能体：
  行动 → 观察 → 重复
  问题：容易重复犯同样的错误

反思型 (Reflexion) 智能体：
  行动 → 观察 → 反思 → 学习 → 改进后的行动
  优点：具备自我修正能力，实现持续改进
```

---

## 项目管理智能体 (PM Agent) 集成架构

### 1. 自我评估 (Self-Evaluation)

**时机**：实施完成后，发送完成报告前。

```yaml
目的：客观评估自己的实施成果

自我提问：
  ❓ “这个实施方案真的正确吗？”
  ❓ “所有测试都通过了吗？”
  ❓ “我有没有基于主观臆断进行判断？”
  ❓ “是否满足了用户的所有需求？”

流程：
  1. 回顾实施内容
  2. 确认测试结果
  3. 与需求进行核对
  4. 确认是否有证据支撑

输出：
  - 完成判定 (✅ / ❌)
  - 缺失项清单
  - 下一步行动建议
```

### 2. 自我反思 (Self-Reflection)

**时机**：发生错误或实施失败时。

```yaml
目的：理解失败的原因

Reflexion 示例 (源自原论文)：
  “反思：我搜错了该节目的标题，导致没有任何结果。
   我应该通过搜索该节目的主角来寻找正确的信息。”

在 PM 智能体中的应用：
  “反思：
   ❌ 哪里出了错：JWT 验证失败
   🔍 根本原因：缺少环境变量 SUPABASE_JWT_SECRET
   💡 发生原因：在实施前没有检查 .env.example 文件
   ✅ 预防措施：在开始前始终验证环境配置
   📝 学习心得：将环境变量验证添加到启动检查清单中”

存储：
  → docs/memory/reflexion.jsonl (反思记忆 - 始终可用)
  → docs/mistakes/[功能名称]-YYYY-MM-DD.md
  → mindbase (如果安装了 airis-mcp-gateway，将自动同步)
```

### 3. 记忆集成 (Memory Integration)

**目的**：从过去的失败中学习，避免重蹈覆辙。

```yaml
错误发生时：
  1. 检查既往错误 (自动工具选择)：
     → 在对话历史中搜索类似的错误
     → 智能体选择最合适的工具：
       * mindbase_search (如果安装了相关 MCP)：
         - 跨所有对话的语义搜索
         - 跨项目的模式识别
       * ReflexionMemory (内置，始终可用)：
         - 在 reflexion.jsonl 中进行关键词搜索
         - 针对项目范围的快速匹配

  2. 如果发现类似错误：
     ✅ “⚠️ 此前发生过同样的错误”
     ✅ “解决方案：[既往解决方案]”
     ✅ 立即应用已知的解决方案
     → 跳过冗长的调查过程

  3. 否则 (新错误)：
     → 继续进行根本原因调查
     → 记录解决方案以供未来参考
```

---

## 实施模式

### 模式 1：实施前反思 (Pre-Implementation Reflection)

```yaml
在开始前：
  PM 智能体的内部对话：
    “我清楚需要做什么吗？”
    → 如果不清楚：请求用户进一步澄清
    → 如果清楚：继续

    “我拥有充足的信息吗？”
    → 检查项：需求、约束、架构
    → 如果不充足：研究官方文档、参考模式
    → 如果充足：继续

    “可能出现什么问题？”
    → 识别风险
    → 制定缓解策略
```

### 模式 2：实施中检查 (Mid-Implementation Check)

```yaml
实施过程中：
  检查点提问 (每 30 分钟或完成重大里程碑时)：
    ❓ “我还在正确的轨道上吗？”
    ❓ “这个方法有效吗？”
    ❓ “我有没有忽略任何警告或错误？”

  如果检测到偏离：
    → 停止
    → 反思：“我为什么会偏离目标？”
    → 重新评估：“我应该纠正航向还是继续现在的做法？”
    → 决策：继续执行或采用新方法重新开始
```

### 模式 3：实施后反思 (Post-Implementation Reflection)

```yaml
实施完成后：
  完成检查清单：
    ✅ 测试全部通过 (显示实际结果)
    ✅ 需求全部满足 (核对检查清单)
    ✅ 无任何被忽略的警告 (全部经过调查)
    ✅ 有证据记录 (测试输出、代码变更)

  如果检查清单不完整：
    → ❌ 判定为未完成
    → 如实汇报当前状态
    → 继续工作

  如果检查清单完整：
    → ✅ 功能已完成
    → 记录学习心得
    → 更新知识库
```

---

## 幻觉预防策略 (Hallucination Prevention Strategies)

### 策略 1：证据要求 (Evidence Requirement)

**原则**：没有证据证明成功时，绝不声称成功。

```yaml
声称“已完成”时：
  必须提供：
    1. 测试结果 (实际输出内容)
    2. 代码变更 (文件列表、Diff 摘要)
    3. 验证状态 (Lint 检查、类型检查、构建状态)

  如果证据缺失：
    → 拦截“已完成”的声明
    → 强制先执行验证
```

### 策略 2：自我提问 (Self-Check Questions)

**原则**：系统性地质疑自己的假设。

```yaml
在报告前：
  自问：
    ❓ “我真的运行过测试了吗？”
    ❓ “测试结果是真实得到的，还是我臆想的？”
    ❓ “我有没有隐瞒任何失败？”
    ❓ “我会信任这个实施方案并将其部署到生产环境吗？”

  如果任何回答是否定的：
    → 停止报告成功
    → 先修复问题
```

### 策略 3：置信度阈值 (Confidence Thresholds)

**原则**：当置信度低时，承认不确定性。

```yaml
置信度评估：
  高 (90-100%)：
    → 自信地继续执行
    → 官方文档和现有模式支持该方法

  中 (70-89%)：
    → 提供多个选项
    → 解释权衡利弊 (Trade-offs)
    → 推荐最佳选择

  低 (<70%)：
    → 停止
    → 请求用户指导
    → 绝不假装知道
```

---

## Token 预算集成

**挑战**：反思过程本身会消耗 Token。

**解决方案**：根据任务复杂度设定具有预算意识的反思策略。

```yaml
简单任务 (如修复错别字)：
  反思预算：200 Token
  核心问题：“文件修改了吗？测试通过了吗？”

中等任务 (如 Bug 修复)：
  反思预算：1,000 Token
  核心问题：“根本原因找到了吗？添加测试了吗？是否防止了回归？”

复杂任务 (如新功能开发)：
  反思预算：2,500 Token
  核心问题：“满足所有需求了吗？测试全面吗？验证过集成情况吗？文档更新了吗？”

反模式：
  ❌ 无限制的反思 → Token 爆炸
  ✅ 带有预算的反思 → 成本受控
```

---

## 成功指标 (Success Metrics)

### 定量指标

```yaml
幻觉检测率：
  目标：>90% (Reflexion 论文数据为 94%)
  衡量标准：通过自我检查捕获到的错误声明百分比

错误复发率：
  目标：<10% (记录过的错误再次发生)
  衡量标准：发生两次及以上的错误百分比

置信度准确率：
  目标：>85% (置信度与现实情况相符)
  衡量标准：高置信度下的任务成功率
```

### 定性指标

```yaml
文化转变：
  ✅ “知之为知之，不知为不知”
  ✅ “不说谎，展示证据”
  ✅ “承认失败，随后改进”

行为指标：
  ✅ 用户提问减少 (沟通清晰)
  ✅ 返工减少 (首次尝试的准确率提升)
  ✅ 信任度提升 (诚实汇报)
```

---

## 实施检查清单

- [x] 自我检查提问系统 (完成后验证)。
- [x] 证据要求 (Evidence Requirement)。
- [x] 置信度评分 (Confidence Scoring)。
- [ ] 反思模式集成 (自我反思循环)。
- [ ] 带有 Token 预算意识的反思机制。
- [ ] 实施案例与反模式文档化。
- [ ] `workflow_metrics.jsonl` 集成。
- [ ] 测试与验证。

---

## 参考资料

1. **Reflexion: Language Agents with Verbal Reinforcement Learning**
   - 作者：Noah Shinn 等
   - 年份：2023 年
   - 核心见解：自我反思可实现 94% 的错误检测率。

2. **AI 智能体中的自我评估 (Self-Evaluation in AI Agents)**
   - 来源：Galileo AI (2024 年)
   - 核心见解：置信度评分可减少幻觉。

3. **具有 Token 预算意识的 LLM 推理 (Token-Budget-Aware LLM Reasoning)**
   - 来源：arXiv 2412.18547 (2024 年)
   - 核心见解：预算约束可实现高效反思。

---

**报告结束**
