# PM 智能体：自主反思与 Token 优化 (Autonomous Reflection)

**版本**：2.0
**状态**：生产环境就绪 (Production Ready)

---

## 🎯 概览

PM 智能体 (Project Management Agent) 的自主反思与 Token 优化系统。旨在解决智能体“**在错误方向上盲目冲刺**”的问题，并建立“**诚实汇报、提供证据**”的执行文化。

### 解决的核心问题

1. **错误的执行方向导致 Token 爆炸**
   - **对策**：Confidence Check (实施前确信度评估)。
   - **效果**：确信度低时主动提问，防止低效的无效开发。

2. **幻觉问题：谎报“已完成”但无证据**
   - **对策**：Evidence Requirement (证据要求协议)。
   - **效果**：必须提供测试结果，否则拦截“任务完成”汇报。

3. **在同一个错误上多次跌倒**
   - **对策**：Reflexion Pattern (反思模式与错误搜索)。
   - **效果**：错误检测率提升至 94%（基于研究论文实证）。

4. **为了反思而消耗过多 Token 的悖论**
   - **对策**：基于任务复杂度的 Token 预算分配。
   - **效果**：按需分配 200 到 2,500 个 Token 用于反思。

---

## 🚀 快速入门

### 针对用户

**会有什么变化？**
- PM 智能体会**在实施前自我评估确信度**。
- **无法提供证据**的完成报告将被系统拦截。
- 智能体会**自动从过去的失败中学习**。

**您会观察到的现象：**
1. 遇到不确定的需求时，它会**坦诚地向您提问确认**（当确信度评分 < 70% 时）。
2. 在汇报完成时，它**一定会附带测试结果证明**。
3. 同一个报错在第二次出现时，它能**立即给出解决方案**。

---

## 📊 系统架构

### 第一层：Confidence Check (实施前校验)
- **目的**：在朝错误方向迈进前及时止损。
- **流程**：
  - **高确信度 (90-100%)**：已确认官方文档，模式明确，直接开始。
  - **中确信度 (70-89%)**：存在多种实现方案，需权衡。行为：向用户提示并给出建议方案。
  - **低确信度 (<70%)**：需求不明或缺乏领域知识。行为：**停止执行**，向用户提问。

### 第二层：Self-Check Protocol (实施后自检)
- **目的**：防范幻觉，强制要求证据。
- **必答问题**：
  - ❓ 测试是否全部通过？（要求运行测试并展示结果）。
  - ❓ 需求是否全部满足？（对比初始需求，列出已完成和缺失项）。
  - ❓ 是否存在盲目假设？（核实是否查阅了文档）。
  - ❓ 证据在哪里？（要求提供：运行结果、修改文件列表、Lint/Typecheck 状态）。

### 第三层：Reflexion Pattern (错误处理)
- **目的**：学习失败经验，杜绝重复性错误。
- **流程**：
  1. **检查历史错误**：自动检索对话历史及 `reflexion.jsonl` 文件。
  2. **发现匹配项**：如果之前解决过同类问题，直接应用方案，跳过冗长的重新排查过程（**节省巨量 Token**）。
  3. **记录新经验**：如果是新错误，排查根因后将其记录到 `docs/memory/reflexion.jsonl` 及 `docs/mistakes/` 目录。

### 第四层：Token-Budget-Aware Reflection (预算感知型反思)
- **目的**：控制反思成本。
- **预算阶梯**：
  - **简单任务 (如改错字)**：预算 200 Token。
  - **中等任务 (如修复 Bug)**：预算 1,000 Token。
  - **复杂任务 (如新特性)**：预算 2,500 Token，包含全面覆盖率验证。

---

## 📈 预期效果

### Token 效率
- **实施前校验**：防止方向性错误，可节省 60% - 95% 的潜在浪费。
- **反思成本**：通过压缩上下文及预算制，反思成本降低 80% - 95%。
- **已知错误解决**：对于重复错误，通过缓存检索实现“零增量”排错。

### 质量提升
- **幻觉拦截率**：基于自检协议，虚假上报的检测率达 94%。
- **错误复发率**：重复性错误发生率降低至 10% 以下。

### 文化转变
- **之前**：❌ “已经修好了！”（无凭无据）；❌ “大概没问题吧”（猜测）；❌ 重复跌倒在坑里。
- **之后**：✅ “15/15 测试通过，覆盖率 87%”；✅ “这里有些不确定，请您指导”；✅ “发现此类错误曾发生过，已应用旧方案解决”。

---

## 📚 参考文献

1. **Reflexion: Language Agents with Verbal Reinforcement Learning** (Noah Shinn et al., 2023) —— 通过自我反思实现 94% 的错误检测。
2. **Token-Budget-Aware LLM Reasoning** (arXiv 2412.18547) —— 基于复杂度的动态 Token 分配。
3. **Anthropic Production Agent Optimization** —— 渐进式加载与工作流指标优化。

---

**文档结束**

*实现细节请参阅 `plugins/superclaude/commands/pm.md` 第 870-1016 行。*
