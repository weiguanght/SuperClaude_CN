# 工作流度量模式 (Workflow Metrics Schema)

**目的**: 跟踪 Token 效率，用于持续优化及 A/B 测试。

**文件**: `docs/memory/workflow_metrics.jsonl` (仅追加日志)

## 数据结构 (JSONL 格式)

每行是一个完整的 JSON 对象，代表一次工作流执行。

```jsonl
{
  "timestamp": "2025-10-17T01:54:21+09:00",
  "session_id": "abc123def456",
  "task_type": "typo_fix",
  "complexity": "light",
  "workflow_id": "progressive_v3_layer2",
  "layers_used": [0, 1, 2],
  "tokens_used": 650,
  "time_ms": 1800,
  "files_read": 1,
  "mindbase_used": false,
  "sub_agents": [],
  "success": true,
  "user_feedback": "satisfied",
  "notes": "Optional implementation notes"
}
```

## 字段定义

### 必填字段

| 字段 | 类型 | 描述 | 示例 |
|-------|------|-------------|---------|
| `timestamp` | ISO 8601 | 执行时间戳 (JST) | `"2025-10-17T01:54:21+09:00"` |
| `session_id` | string | 会话唯一标识符 | `"abc123def456"` |
| `task_type` | string | 任务分类 | `"typo_fix"`, `"bug_fix"`, `"feature_impl"` |
| `complexity` | string | 意图分类级别 | `"ultra-light"`, `"light"`, `"medium"`, `"heavy"`, `"ultra-heavy"` |
| `workflow_id` | string | 工作流变体标识符 | `"progressive_v3_layer2"` |
| `layers_used` | array | 执行的渐进加载层 | `[0, 1, 2]` |
| `tokens_used` | integer | 消耗的总 Token 数 | `650` |
| `time_ms` | integer | 执行时间 (毫秒) | `1800` |
| `success` | boolean | 任务完成状态 | `true`, `false` |

### 可选字段

| 字段 | 类型 | 描述 | 示例 |
|-------|------|-------------|---------|
| `files_read` | integer | 读取文件数 | `1` |
| `error_search_tool` | string | 错误搜索工具 | `"mindbase_search"`, `"ReflexionMemory"`, `"none"` |
| `sub_agents` | array | 委派的子智能体 | `["backend-architect", "quality-engineer"]` |
| `user_feedback` | string | 推断的用户满意度 | `"satisfied"`, `"neutral"`, `"unsatisfied"` |
| `notes` | string | 实施备注 | `"Used cached solution"` |
| `confidence_score` | float | 实施前置信度 | `0.85` |
| `hallucination_detected` | boolean | 发现自检红旗 | `false` |
| `error_recurrence` | boolean | 遇到相同错误 | `false` |

## 任务类型分类体系

### 超轻量任务 (Ultra-Light)
- `progress_query`: "进度查询"
- `status_check`: "现状确认"
- `next_action_query`: "下一步是什么？"

### 轻量任务 (Light)
- `typo_fix`: 修正 README 错别字
- `comment_addition`: 添加注释
- `variable_rename`: 变量重命名
- `documentation_update`: 文档更新

### 中等任务 (Medium)
- `bug_fix`: Bug 修复
- `small_feature`: 小功能追加
- `refactoring`: 重构
- `test_addition`: 添加测试

###通过重任务 (Heavy)
- `feature_impl`: 新功能实现
- `architecture_change`: 架构变更
- `security_audit`: 安全审计
- `integration`: 外部系统集成

### 超重任务 (Ultra-Heavy)
- `system_redesign`: 系统全面重设计
- `framework_migration`: 框架迁移
- `comprehensive_research`: 全面调研

## 工作流变体标识符

### 渐进加载变体
- `progressive_v3_layer1`: 超轻量 (仅记忆文件)
- `progressive_v3_layer2`: 轻量 (仅目标文件)
- `progressive_v3_layer3`: 中等 (相关文件 3-5 个)
- `progressive_v3_layer4`: 重 (子系统)
- `progressive_v3_layer5`: 超重 (全量 + 外部调研)

### 实验性变体 (A/B 测试)
- `experimental_eager_layer3`: 中等任务总是加载 Layer 3
- `experimental_lazy_layer2`: 最小化 Layer 2 加载
- `experimental_parallel_layer3`: Layer 3 并行文件加载

## 复杂性分类规则

```yaml
ultra_light:
  keywords: ["进捗", "状况", "进展", "where", "status", "progress"]
  token_budget: "100-500"
  layers: [0, 1]

light:
  keywords: ["错字", "typo", "fix typo", "correct", "comment"]
  token_budget: "500-2K"
  layers: [0, 1, 2]

medium:
  keywords: ["Bug", "bug", "fix", "修正", "error", "issue"]
  token_budget: "2-5K"
  layers: [0, 1, 2, 3]

heavy:
  keywords: ["新功能", "new feature", "implement", "实现"]
  token_budget: "5-20K"
  layers: [0, 1, 2, 3, 4]

ultra_heavy:
  keywords: ["重设计", "redesign", "overhaul", "migration"]
  token_budget: "20K+"
  layers: [0, 1, 2, 3, 4, 5]
```

## 记录点 (Recording Points)

### 会话开始 (Layer 0)
```python
session_id = generate_session_id()
workflow_metrics = {
    "timestamp": get_current_time(),
    "session_id": session_id,
    "workflow_id": "progressive_v3_layer0"
}
# 引导开销: 150 tokens
```

### 意图分类后 (Layer 1)
```python
workflow_metrics.update({
    "task_type": classify_task_type(user_request),
    "complexity": classify_complexity(user_request),
    "estimated_token_budget": get_budget(complexity)
})
```

### 渐进加载后
```python
workflow_metrics.update({
    "layers_used": [0, 1, 2],  # 实际执行的层
    "tokens_used": calculate_tokens(),
    "files_read": len(files_loaded)
})
```

### 任务完成后
```python
workflow_metrics.update({
    "success": task_completed_successfully,
    "time_ms": execution_time_ms,
    "user_feedback": infer_user_satisfaction()
})
```

### 会话结束
```python
# 追加到 workflow_metrics.jsonl
with open("docs/memory/workflow_metrics.jsonl", "a") as f:
    f.write(json.dumps(workflow_metrics) + "\n")
```

## 分析脚本

### 每周分析
```bash
# 按任务类型分组并计算平均值
python scripts/analyze_workflow_metrics.py --period week

# 输出:
# Task Type: typo_fix
#   Count: 12
#   Avg Tokens: 680
#   Avg Time: 1,850ms
#   Success Rate: 100%
```

### A/B 测试分析
```bash
# 比较工作流变体
python scripts/ab_test_workflows.py \
  --variant-a progressive_v3_layer2 \
  --variant-b experimental_eager_layer3 \
  --metric tokens_used

# 输出:
# Variant A (progressive_v3_layer2):
#   Avg Tokens: 1,250
#   Success Rate: 95%
#
# Variant B (experimental_eager_layer3):
#   Avg Tokens: 2,100
#   Success Rate: 98%
#
# 统计显著性: p = 0.03 (显著)
# 建议: 保持 Variant A (效率更高)
```

## 使用 (持续优化)

### 每周回顾流程
```yaml
every_monday_morning:
  1. 运行分析: python scripts/analyze_workflow_metrics.py --period week
  2. 识别模式:
     - 每种任务类型的最佳工作流
     - 低效模式 (高 Token, 低成功率)
     - 用户满意度趋势
  3. 更新建议:
     - 将高效工作流提升为标准
     - 弃用低效工作流
     - 设计新的实验变体
```

### A/B 测试框架
```yaml
allocation_strategy:
  current_best: 80%  # 使用当前最佳工作流
  experimental: 20%  # 测试新变体

evaluation_criteria:
  minimum_trials: 20  # 每个变体最少试验次数
  confidence_level: 0.95  # p < 0.05
  metrics:
    - tokens_used (主要)
    - success_rate (门槛: 必须 ≥95%)
    - user_feedback (定性)

promotion_rules:
  if experimental_better:
    - 统计显著性确认
    - 成功率 ≥ current_best
    - 用户反馈 ≥ neutral
    → 提升为标准 (80% 分配)

  if experimental_worse:
    → 弃用变体
    → 在 docs/patterns/ 中记录教训
```

### 自动优化循环
```yaml
monthly_cleanup:
  1. 识别陈旧工作流:
     - 过去 90 天无使用
     - 成功率 <80%
     - 用户反馈持续负面

  2. 归档弃用工作流:
     - 移至 docs/patterns/deprecated/
     - 记录弃用原因

  3. 提升新标准:
     - Experimental → Standard (如果证明更好)
     - 用新最佳实践更新 pm.md

  4. 生成月度报告:
     - Token 效率趋势
     - 成功率提升
     - 用户满意度演变
```

## 可视化

### Token 使用随时间变化
```python
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_json("docs/memory/workflow_metrics.jsonl", lines=True)
df['date'] = pd.to_datetime(df['timestamp']).dt.date

daily_avg = df.groupby('date')['tokens_used'].mean()
plt.plot(daily_avg)
plt.title("Average Token Usage Over Time")
plt.ylabel("Tokens")
plt.xlabel("Date")
plt.show()
```

### 任务类型分布
```python
task_counts = df['task_type'].value_counts()
plt.pie(task_counts, labels=task_counts.index, autopct='%1.1f%%')
plt.title("Task Type Distribution")
plt.show()
```

### 工作流效率对比
```python
workflow_efficiency = df.groupby('workflow_id').agg({
    'tokens_used': 'mean',
    'success': 'mean',
    'time_ms': 'mean'
})
print(workflow_efficiency.sort_values('tokens_used'))
```

## 预期模式

### 健康指标 (1个月后)
```yaml
token_efficiency:
  ultra_light: 750-1,050 tokens (削减 63%)
  light: 1,250 tokens (削减 46%)
  medium: 3,850 tokens (削减 47%)
  heavy: 10,350 tokens (削减 40%)

success_rates:
  all_tasks: ≥95%
  ultra_light: 100% (简单任务)
  light: 98%
  medium: 95%
  heavy: 92%

user_satisfaction:
  satisfied: ≥70%
  neutral: ≤25%
  unsatisfied: ≤5%
```

### 红色警报 (需要调查)
```yaml
warning_signs:
  - 任一任务类型成功率 < 85%
  - tokens_used > 预估预算 30% 以上
  - light 任务耗时 > 10秒
  - 用户反馈 "unsatisfied" > 10%
  - 错误复发率 > 15%
```

## 与 PM 智能体的集成

### 自动记录
PM 智能体在每个执行点自动记录指标：
- 会话开始 (Layer 0)
- 意图分类 (Layer 1)
- 渐进加载 (Layers 2-5)
- 任务完成
- 会话结束

### 无需人工干预
- 所有记录均为自动
- 无需用户操作
- 透明运行
- 隐私保护 (仅本地文件)

## 隐私与安全

### 数据保留
- 仅本地存储 (`docs/memory/`)
- 无外部传输
- 这里的 Git 管理 (可选)
- 用户控制保留期限

### 敏感数据处理
- 不记录代码片段
- 不记录用户输入内容
- 仅记录元数据 (tokens, 计时, 成功状态)
- 任务类型为通用分类

## 维护

### 文件轮转
```bash
# 归档旧指标 (月度)
mv docs/memory/workflow_metrics.jsonl \
   docs/memory/archive/workflow_metrics_2025-10.jsonl

# 重新开始
touch docs/memory/workflow_metrics.jsonl
```

### 清理
```bash
# 删除超过 6 个月的指标
find docs/memory/archive/ -name "workflow_metrics_*.jsonl" \
  -mtime +180 -delete
```

## 参考
- 规格: `plugins/superclaude/commands/pm.md` (行 291-355)
- 研究: `docs/research/llm-agent-token-efficiency-2025.md`
- 测试: `tests/pm_agent/test_token_budget.py`
